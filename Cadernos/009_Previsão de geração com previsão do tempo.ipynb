{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import random\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "from feature_engine.creation import RelativeFeatures\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.timeseries.forecasting import LagFeatures\n",
    "from feature_engine.timeseries.forecasting import WindowFeatures\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sktime.split import temporal_train_test_split\n",
    "from sktime.utils import plotting\n",
    "\n",
    "from statistics import mean \n",
    "from statistics import stdev\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508b961",
   "metadata": {},
   "source": [
    "# Previsão da geração de energia elétrica para o Conjunto Eólico Umburanas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4772b",
   "metadata": {},
   "source": [
    "Horizonte de previsão: 36 horas no futuro\n",
    "\n",
    "Dados de entrada:\n",
    "- Histórico de geração verificada horária\n",
    "- Histórico da velocidade do vento, com granularidade horária\n",
    "- Velocidade do vento nos instantes \"futuros\", com granularidade horária, tomados, neste ensaio, como substitutos perfeitos para a previsão da velocidade do vento\n",
    "\n",
    "Algoritmos de aprendizagem de máquina utilizados:\n",
    "- Regressão linear regularizada \"_ridge_\"\n",
    "- Floresta aleatória\n",
    "- Regressor \"_Light Gradient Boosted Machine_\" (_LightGBM_)\n",
    "- Regressor \"_Extreme Gradient Boosted_\" (_XGBoost_)\n",
    "\n",
    "Técnicas de ajuste de hiperparâmetros utilizadas:\n",
    "- Busca em grade\n",
    "- Busca aleatória\n",
    "\n",
    "Métrica de desempenho:\n",
    "- Raiz do erro quadrático médio\n",
    "\n",
    "Técnicas de estimação de desempenho e validação cruzada:\n",
    "- Validação cruzada para séries temporais\n",
    "\n",
    "Parâmetro de comparação:\n",
    "- Curva de geração programada pelo Operador Nacional do Sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a379023",
   "metadata": {},
   "source": [
    "## Leitura e tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo dados de geração em usinas eólicas\n",
    "df_umburanas = pd.read_csv(r\"..\\Dados tratados\\geracao e tempo - umburanas-ba.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf098be",
   "metadata": {},
   "source": [
    "### Conjunto Umburanas - Bahia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c27c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_umburanas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for the transformation: Feature Engineering for Time Series Forecasting, https://www.trainindata.com/\n",
    "df_umburanas[\"Data\"] = pd.to_datetime(df_umburanas[\"Data\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df_umburanas = df_umburanas.set_index(\"Data\")\n",
    "df_umburanas.sort_index(inplace=True)\n",
    "df_umburanas = df_umburanas.asfreq(\"1h\", method = \"ffill\")\n",
    "df_umburanas.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fdca4a",
   "metadata": {},
   "source": [
    "## Previsão da geração de energia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ec553",
   "metadata": {},
   "source": [
    "### Criação de parâmetros para o treinamento de modelos de previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e6673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df_umburanas.copy()\n",
    "df.rename(columns={\"velocidade_vento\":\"vento_t\",\n",
    "                   \"Geração verificada\":\"g_ver_t\",\n",
    "                   \"Geração programada\":\"g_prog_t\"\n",
    "                  },inplace=True)\n",
    "\n",
    "\n",
    "baseline = pd.DataFrame(df[[\"g_prog_t\"]])\n",
    "df.drop([\"g_prog_t\"], axis=1, inplace=True)\n",
    "df = df[[\"vento_t\",\"g_ver_t\"]]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"previsao_vento_t\"] = df[\"vento_t\"].shift(-13)\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08e764",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05849d35",
   "metadata": {},
   "source": [
    "#### Construção de atributos preditivos\n",
    "\n",
    "E se utilizássemos dados da previsão meteorológica para o treinamento do modelo?\n",
    "\n",
    "Previsões meteorológicas não foram extraídas da API do Open-Meteo, apenas os dados históricos da velocidade do vento. Assim, no lugar das previsões meteorológicas, serão utilizados os dados históricos da velocidade do vento, tomados como substitutos \"perfeitos\".\n",
    "\n",
    "Note que, no instante da programação, tais medições não estariam disponíveis no instante da previsão da geração eólica, pois os valores medidos para a velocidade do vento local se referem a instantes no futuro, posteriores à previsão. \n",
    "\n",
    "\n",
    "É importante lembrar que, para se utilizar um modelo em um contexto real, só é possível utilizar as informações que estejam disponíveis no momento da previsão. Isso exclui informações desconhecidas acerca do futuro, porém inclui informações conhecidas acerca do passado e estimativas e previsões acerca do futuro.\n",
    "\n",
    "Para criar um modelo mais realista, deveria-se utilizar, em vez de medições reais da velocidade do vento, informações referentes a modelos de previsão meteorológica, que estariam disponíveis aos agentes de programação no momento da previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae74a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção de atributos preditivos\n",
    "\n",
    "# Adaptado do material disponível no curso \"Feature engineering for time series forecasting\"\n",
    "# https://github.com/trainindata/feature-engineering-for-time-series-forecasting/tree/main/03-Challenges-in-Time-Series-Forecasting\n",
    "\n",
    "# Atributos temporais\n",
    "atributos_temporais = DatetimeFeatures(variables=\"index\",features_to_extract=[\"month\",\"hour\"])\n",
    "\n",
    "# Atributos de atraso\n",
    "atributos_atraso = LagFeatures(variables=[\"g_ver_t\",\"vento_t\"], \n",
    "                               freq = [\"1H\",\"2H\",\"12H\",\"24H\",\"36H\"],\n",
    "                               missing_values=\"ignore\")\n",
    "\n",
    "atributos_avanco = LagFeatures(variables=[\"previsao_vento_t\"],\n",
    "                              freq = [\"12H\",\"11H\",\"10H\",\"7H\",\"4H\",\"1H\"],\n",
    "                              missing_values=\"ignore\")\n",
    "\n",
    "# Atributos agregados em janelas\n",
    "atributos_media_movel = WindowFeatures(variables=[\"g_ver_t\",\"vento_t\"],functions=[\"mean\"], window = [\"3H\",\"6H\",\"24H\",\"36H\"],\n",
    "                                 freq=\"1H\", missing_values = \"ignore\")\n",
    "\n",
    "# Atributos cíclicos relacionados à sazonalidade\n",
    "atributos_ciclicos = CyclicalFeatures(variables=[\"month\",\"hour\"], drop_original=True)\n",
    "\n",
    "# Atributos subtrativos\n",
    "atributos_subtrativos_g = RelativeFeatures(variables=[\"g_ver_t_lag_1H\"], reference=[\"g_ver_t_lag_2H\"], func=[\"sub\"])\n",
    "atributos_subtrativos_v = RelativeFeatures(variables=[\"vento_t_lag_1H\"], reference=[\"vento_t_lag_24H\"], func=[\"sub\"])\n",
    "\n",
    "# Remoção de dados faltantes\n",
    "remocao_faltantes = DropMissingData()\n",
    "\n",
    "# Remoção dos atributos originais (isto é, atributos a serem previstos)\n",
    "remocao_de_atributos = DropFeatures(features_to_drop=[\"g_ver_t\",\"vento_t\",\"previsao_vento_t\"])\n",
    "\n",
    "pipeline2 = Pipeline(\n",
    "    [\n",
    "        \n",
    "        (\"normalizador\", SklearnTransformerWrapper(\n",
    "           transformer = StandardScaler(),\n",
    "          variables = [\"g_ver_t\",\"vento_t\",\"previsao_vento_t\"]\n",
    "         )\n",
    "        ),\n",
    "        (\"atributos_temporais\", atributos_temporais),\n",
    "        (\"atributos_atraso\", atributos_atraso),\n",
    "        (\"atributos_avanco\", atributos_avanco),\n",
    "        (\"atributos_media_movel\", atributos_media_movel),\n",
    "        (\"atributos_ciclicos\", atributos_ciclicos),\n",
    "        (\"remocao_faltantes\", remocao_faltantes),\n",
    "        (\"atributos_subtrativos_g\", atributos_subtrativos_g),\n",
    "        (\"atributos_subtrativos_v\", atributos_subtrativos_v),\n",
    "        (\"remocao_de_atributos\", remocao_de_atributos)\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226837e9",
   "metadata": {},
   "source": [
    "## Divisão do conjunto de dados em um conjunto para treinamento e outro para teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38894e5",
   "metadata": {},
   "source": [
    "Criação de seis conjuntos de dados, sendo cada um deles dividido em um conjunto para treinamento e outro para teste:\n",
    "- Conjunto #1: Treinamento: de 01/01/2021 a 30/06/2021; Teste: a partir de 01/07/2021\n",
    "- Conjunto #2: Treinamento: de 01/01/2021 a 31/12/2021; Teste: a partir de 01/01/2022\n",
    "- Conjunto #3: Treinamento: de 01/01/2021 a 30/06/2022; Teste: a partir de 01/07/2022\n",
    "- Conjunto #4: Treinamento: de 01/01/2021 a 31/12/2022; Teste: a partir de 01/01/2023\n",
    "- Conjunto #5: Treinamento: de 01/01/2021 a 30/06/2023; Teste: a partir de 01/07/2023\n",
    "- Conjunto #6: Treinamento: de 01/01/2021 a 01/10/2023; Teste: a partir de 01/10/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff_dates = [\"2021-03-31\",\"2021-06-30\",\"2021-09-30\",\"2021-12-31\",\n",
    "                      \"2022-03-31\",\"2022-06-30\",\"2022-09-30\",\"2022-12-31\",\n",
    "                      \"2023-03-31\",\"2023-06-30\",\"2023-09-30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0773e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado do material disponível no curso \"Feature engineering for time series forecasting\"\n",
    "# https://github.com/trainindata/feature-engineering-for-time-series-forecasting/tree/main/03-Challenges-in-Time-Series-Forecasting\n",
    "\n",
    "def split_train_test(dataset, cutoff_date, forecast_horizon = 36, target_variables=[]):\n",
    "    test_start_date = pd.to_datetime(cutoff_date) - timedelta(hours = forecast_horizon)\n",
    "    X_train, X_test = dataset[dataset.index < cutoff_date] , dataset[dataset.index >= test_start_date]\n",
    "    \n",
    "    if len(target_variables)== 0:\n",
    "        print(\"Erro: não foram indicadas as variáveis a serem previstas.\")\n",
    "        return\n",
    "    else:\n",
    "        y_train, y_test = dataset[dataset.index < cutoff_date][target_variables], dataset[dataset.index >= test_start_date][target_variables]\n",
    "        return (X_train, X_test, y_train, y_test)\n",
    "        \n",
    "def split_baseline_dataset(baseline_df, cutoff_date, forecast_horizon = 36, baseline_variables=[]):\n",
    "    test_start_date = pd.to_datetime(cutoff_date) - timedelta(hours = forecast_horizon)\n",
    "    if len(baseline_variables)== 0:\n",
    "        print(\"Erro: não foram indicadas as variáveis de base a servirem de comparação.\")\n",
    "        return\n",
    "    else:\n",
    "        baseline_train, baseline_test = baseline_df[baseline_df.index < cutoff_date][baseline_variables], baseline_df[baseline_df.index >= test_start_date][baseline_variables]\n",
    "        return(baseline_train, baseline_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(dataset = df, \n",
    "                                                    cutoff_date = \"2023-10-01\", \n",
    "                                                    forecast_horizon = 36, \n",
    "                                                    target_variables=[\"vento_t\",\"g_ver_t\"])\n",
    "\n",
    "baseline_train, baseline_test = split_baseline_dataset(baseline_df = baseline, \n",
    "                                                       cutoff_date = \"2023-10-01\",\n",
    "                                                       forecast_horizon = 36, \n",
    "                                                       baseline_variables = [\"g_prog_t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features_train_set(pipeline, X_train, y_train):\n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    train_indices = X_train.index\n",
    "    y_train = y_train.loc[train_indices]\n",
    "    return(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51505e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_transformed, y_train_transformed = transform_features_train_set(pipeline2, X_train, y_train)\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdac642",
   "metadata": {},
   "source": [
    "## Escolha dos modelos de aprendizagem de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613983b3",
   "metadata": {},
   "source": [
    "- Modelo 1: Regressão linear regularizada Ridge\n",
    "- Modelo 2: Árvore aleatória\n",
    "- Modelo 3: Light Gradient Boosted Machine\n",
    "- Modelo 4: Extreme Gradient Boosted Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fdf64",
   "metadata": {},
   "source": [
    "## Seleção e ajuste de hiperparâmetros dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado do material disponível no curso \"Feature engineering for time series forecasting\"\n",
    "# https://github.com/trainindata/feature-engineering-for-time-series-forecasting/tree/main/03-Challenges-in-Time-Series-Forecasting\n",
    "\n",
    "def make_forecast_wind_generation(model, X, y, target_variables, forecast_point_start, forecast_horizon, pipeline, baseline = None, show_plot = True):\n",
    "    \"\"\" Realiza uma previsão de valores recursiva para uma série temporal e calcula a raiz do erro quadrático médio das previsões.\n",
    "\n",
    "        Parâmetros de entrada:\n",
    "            model -- Modelo de predição que gerará as previsões. O modelo deve ser fornecido após já ter sido treinado com os dados de treinamento.\n",
    "            X -- Conjunto de dados separado para o teste do modelo de previsão;\n",
    "            y -- Valores reais a serem previstos.\n",
    "            target_variables -- Lista de variáveis a serem previstas. A última variável deve ser a variável principal a ser prevista.\n",
    "            forecast_point_start -- Data a partir da qual deve-se gerar previsões para a variável alvo\n",
    "            forecast_horizon -- Horizonte de previsão. Indica a quantidade de horas a serem previstas a partir da data indicada.\n",
    "            pipeline -- Sequência de operações de transformação a serem aplicadas sobre os dados de entrada.\n",
    "            baseline -- Valores com as quais as previsões serão comparadas.\n",
    "            show_plot -- Booleano que indica se a função deve ou não criar gráficos comparando os valores previstos e reais.\n",
    "\n",
    "        Variáveis de saída:\n",
    "            forecasted_values -- Valores previstos pelo modelo. DataFrame com um número de linhas igual ao horizonte de previsão.\n",
    "            rmse_predicted -- Raiz do erro quadrático médio dos valores previstos em comparação aos valores esperados\n",
    "            rmse_baseline -- Raiz do erro quadrático médio dos valores do conjunto de base em comparação aos valores esperados.\n",
    "    \"\"\"\n",
    "    \n",
    "    forecast_point_start = pd.to_datetime(forecast_point_start) # Primeiro instante para o qual uma previsão será gerada\n",
    "    forecast_point_end = forecast_point_start + timedelta(hours = forecast_horizon - 1) # Último instante para o qual uma previsão será gerada\n",
    "    forecast_indices =  pd.date_range(start=forecast_point_start, end=forecast_point_end, freq=\"1H\") # Instantes de tempo para os quais uma previsão será gerada\n",
    "    forecasted_values = pd.DataFrame(index = forecast_indices, columns = target_variables) # DataFrame com os valores previstos pelo modelo\n",
    "    forecast_point = forecast_point_start # Instante de previsão atual. Varia entre os instantes de previsão inicial e final.\n",
    "    \n",
    "    # Determina a janela de seleção dos dados de teste\n",
    "    # Os dados de teste relativos à algumas horas antes do primeiro ponto de previsão\n",
    "    # serão utilizados no cálculo das variáveis de atraso\n",
    "    input_window_start = forecast_point - timedelta(hours = forecast_horizon)\n",
    "    input_window_end = forecast_point - timedelta(hours = 1)    \n",
    "    input_window =  pd.date_range(start=input_window_start, end=input_window_end, freq=\"1H\") # Instantes de tempo para os quais uma previsão será gerada\n",
    "\n",
    "    pipeline_inputs = X.loc[input_window]\n",
    "    pipeline_inputs.loc[forecast_point] = X.loc[forecast_point]\n",
    "    pipeline_inputs.loc[forecast_point, target_variables] = 0 # Instante para o qual a previsão será realizada. Após ser previsto, este valor servirá de entrada para a previsões futuras.\n",
    "    \n",
    "    pipeline_outputs = pipeline.transform(pipeline_inputs) # Cria atributos preditivos a partir dos dados de teste\n",
    "    \n",
    "    prediction = model.predict(pipeline_outputs) # Calcula o valor previsto para um instante de tempo  \n",
    "    forecasted_values.loc[forecast_point, target_variables] = prediction # Armazena o valor previsto   \n",
    "    pipeline_inputs.loc[forecast_point, target_variables] = prediction # Predição recursiva: adiciona o valor previsto para ser usado como entrada para a próxima previsão\n",
    "\n",
    "    # Repete as previsões ao longo da janela de previsão\n",
    "    for t in range(forecast_horizon - 1):\n",
    "        forecast_point = forecast_point + timedelta(hours = 1) # Avança o ponto de previsão uma hora para a frente\n",
    "        input_window = input_window + timedelta(hours = 1) # Move a janela de seleção dos dados de teste em uma hora para a frente\n",
    "\n",
    "        pipeline_inputs = pipeline_inputs.loc[input_window]\n",
    "        pipeline_inputs.loc[forecast_point] = X.loc[forecast_point]\n",
    "        pipeline_inputs.loc[forecast_point, target_variables] = 0 # Instante para o qual a previsão será realizada. Após ser previsto, este valor servirá de entrada para a previsões futuras.\n",
    "    \n",
    "        pipeline_outputs = pipeline.transform(pipeline_inputs) # Cria atributos preditivos a partir dos dados de teste\n",
    "        prediction = model.predict(pipeline_outputs) # Calcula o valor previsto para um instante de tempo  \n",
    "        \n",
    "        forecasted_values.loc[forecast_point, target_variables] = prediction # Armazena o valor previsto  \n",
    "        pipeline_inputs.loc[forecast_point, target_variables] = prediction # Predição recursiva: adiciona o valor previsto para ser usado como entrada para a próxima previsão\n",
    "        \n",
    "    # Extrai os valores previstos referentes à variável principal\n",
    "    forecasted_values = forecasted_values[\"g_ver_t\"]\n",
    "\n",
    "    # Extrai os valores de teste relativos ao intervalo de tempo da predição\n",
    "    expected_values = X.loc[forecast_indices][\"g_ver_t\"] \n",
    "    comparison = pd.merge(forecasted_values, expected_values, left_index = True, right_index=True)\n",
    "    comparison.columns = [\"Previsto\", \"Verificado\"]\n",
    "    \n",
    "    if baseline is not None:\n",
    "        # Extrai os valores programados relativos ao intervalo de tempo da predição\n",
    "        programmed_values = baseline.loc[forecast_indices][\"g_prog_t\"]\n",
    "        comparison = pd.merge(comparison, programmed_values, left_index = True, right_index=True)\n",
    "        comparison.columns = [\"Previsto\", \"Verificado\", \"Programado\"]\n",
    "    \n",
    "    rmse_pred = None\n",
    "    rmse_prog = None\n",
    "    \n",
    "    # Calcula a raiz do erro quadrático médio dos valores previstos\n",
    "    rmse_pred = mean_squared_error(y_true=comparison[\"Verificado\"],\n",
    "                                   y_pred=comparison[\"Previsto\"], squared=False)\n",
    "    \n",
    "    if baseline is not None:\n",
    "        # Calcula a raiz do erro quadrático médio dos valores programados\n",
    "        rmse_prog = mean_squared_error(y_true=comparison[\"Verificado\"], \n",
    "                                   y_pred=comparison[\"Programado\"], squared=False)\n",
    "    \n",
    "    # Cria um gráfico mostrando os valores previstos, esperados e programados\n",
    "    if show_plot:\n",
    "        comparison.plot.line(xlabel = \"Data e hora\", ylabel=\"Geração eólica (MW-médio horário)\")\n",
    "        plt.show()\n",
    "    \n",
    "    return(forecasted_values, rmse_pred, rmse_prog)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4351f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado do material disponível no curso \"Feature engineering for time series forecasting\"\n",
    "# https://github.com/trainindata/feature-engineering-for-time-series-forecasting/tree/main/03-Challenges-in-Time-Series-Forecasting\n",
    "\n",
    "def rolling_forecast_evaluation(dataset, model, pipeline, train_cutoff_dates, forecast_horizon, target_variables, baseline, show_test_plots = True):\n",
    "    \"\"\" Divide o conjunto de dados em vários conjuntos de treinamento e teste, tomados em sequência,\n",
    "        treina um modelo de previsão para cada conjunto de teste\n",
    "        e avalia o desempenho médio de modelos de previsão sobre os conjuntos de teste.\n",
    "\n",
    "        Parâmetros de entrada:\n",
    "            dataset -- O conjunto de dados a ser usado para o treinamento e avaliação dos modelos preditivos\n",
    "            model -- Modelo de predição que gerará as previsões. O modelo deve ser fornecido após já ter sido treinado com os dados de treinamento.\n",
    "            pipeline -- Sequência de operações de transformação a serem aplicadas sobre os dados de entrada.\n",
    "            train_cutoff_dates -- Lista contendo datas que serão utilizadas para dividir o conjunto de dados em vários conjuntos de treinamento e teste\n",
    "            forecast_horizon -- Horizonte de previsão. Indica a quantidade de horas a serem previstas a partir da data indicada.\n",
    "            target_variables -- Lista de variáveis a serem previstas. A última variável deve ser a variável principal a ser prevista.\n",
    "            baseline -- Valores com as quais as previsões serão comparadas. \n",
    "            show_test_plots -- Booleano. Usado para ativar ou desativar a geração de gráficos de previsão para o conjunto de testes.\n",
    "\n",
    "        Variáveis de saída:\n",
    "            rmse_pred_train -- RMSE dos modelos de predição quando os dados de treinamento são usados como entrada\n",
    "            rmse_pred_test -- RMSE dos modelos de predição quando os dados de teste são usados como entrada\n",
    "            rmse_prog -- RMSE médio dos valores do conjunto de base em comparação aos valores esperados.\n",
    "    \"\"\"\n",
    "    rmse_pred_train=[]  \n",
    "    rmse_pred_test=[]\n",
    "    rmse_prog=[]\n",
    "\n",
    "    for cutoff_date in train_cutoff_dates:\n",
    "        X_train, X_test, y_train, y_test = split_train_test(dataset=dataset, \n",
    "                                                            cutoff_date=cutoff_date, \n",
    "                                                            forecast_horizon = forecast_horizon, \n",
    "                                                            target_variables=target_variables)\n",
    "        X_train_transformed, y_train_transformed = transform_features_train_set(pipeline, X_train, y_train)\n",
    "        \n",
    "        model.fit(X_train_transformed, y_train_transformed)\n",
    "\n",
    "        # Estimação do desempenho do modelo de predição quando aplicado ao conjunto de treinamento\n",
    "        forecasted_values, rmse_predicted_train, rmse_baseline = make_forecast_wind_generation(\n",
    "            model=model, X=X_train, y=y_train, \n",
    "            target_variables=target_variables, \n",
    "            forecast_point_start=pd.to_datetime(cutoff_date) - timedelta(hours =  forecast_horizon), \n",
    "            forecast_horizon=forecast_horizon,\n",
    "            pipeline=pipeline,\n",
    "            show_plot = False)\n",
    "\n",
    "        # Estimação do desempenho do modelo de predição quando aplicado ao conjunto de teste\n",
    "        forecasted_values, rmse_predicted_test, rmse_baseline = make_forecast_wind_generation(\n",
    "            model=model, X=X_test, y=y_test, \n",
    "            target_variables=target_variables, \n",
    "            forecast_point_start=cutoff_date,\n",
    "            forecast_horizon=forecast_horizon, pipeline=pipeline, baseline=baseline,\n",
    "            show_plot = show_test_plots)\n",
    "\n",
    "        rmse_pred_train.append(rmse_predicted_train)\n",
    "        rmse_pred_test.append(rmse_predicted_test)\n",
    "        rmse_prog.append(rmse_baseline)\n",
    "        \n",
    "    return((rmse_pred_train), (rmse_pred_test), (rmse_prog))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d13c23",
   "metadata": {},
   "source": [
    "### Modelo 5 - Regressão linear regularizada Ridge com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e66d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search_results = {}\n",
    "\n",
    "\n",
    "for i, alpha in enumerate(hyperparameters[\"alpha\"]):\n",
    "    print(f\"Variation {i}; alpha = {alpha}\")\n",
    "    model_5 = Ridge(alpha=alpha)\n",
    "    rmse_pred_train, rmse_pred_test, rmse_prog = rolling_forecast_evaluation(dataset=df,\n",
    "                                model=model_5,\n",
    "                                pipeline=pipeline2,\n",
    "                                train_cutoff_dates=train_cutoff_dates,\n",
    "                                forecast_horizon=36,\n",
    "                                target_variables=[\"g_ver_t\"],\n",
    "                                baseline=baseline,\n",
    "                                show_test_plots=False)\n",
    "    \n",
    "    grid_search_results[str(i)]={\n",
    "        \"alpha\":alpha,\n",
    "        \"rmse_pred_train_avg\":mean(rmse_pred_train),\n",
    "        \"rmse_pred_train_stdev\":stdev(rmse_pred_train),\n",
    "        \"rmse_pred_test_avg\":mean(rmse_pred_test),\n",
    "        \"rmse_pred_test_stdev\":stdev(rmse_pred_test),\n",
    "        \"rmse_prog_avg\":mean(rmse_prog),\n",
    "        \"rmse_prog_stdev\":stdev(rmse_prog)\n",
    "    }\n",
    "\n",
    "df_grid_search_results = pd.DataFrame.from_dict(grid_search_results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004fcc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_grid_search_results = df_grid_search_results.sort_values(by=[\"rmse_pred_test_avg\"])\n",
    "df_grid_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81e888",
   "metadata": {},
   "source": [
    "Modelos menos regularizados apresentaram os menores valores de RMSE.\n",
    "Hiperparâmetro selecionado para a o regressor linear RIDGE:\n",
    "- Alpha (regularização): 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a891d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_search_results.to_csv(r\"model_5_ridge_grid_search_results.csv\", encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97cbdbd",
   "metadata": {},
   "source": [
    "### Modelo 6 - Floresta aleatória com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f0d55",
   "metadata": {},
   "source": [
    "#### Ajuste de hiperparâmetros - busca aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7371f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "random.seed(23) # inicializando o gerador de números pseudo-aleatórios com uma \"semente\" para que os resultados sejam os mesmos para cada vez que este código for executado\n",
    "\n",
    "random_search_results = {}\n",
    "\n",
    "df_random_search_results = pd.DataFrame()\n",
    "\n",
    "for i in range(37):\n",
    "    if i == 0: # utilize os hiperparâmetros padrão no primeiro modelo\n",
    "        n_estimators=100 # Número de árvores de decisão a serem treinadas e agrupadas\n",
    "        max_depth = None # Profundidade máxima de cada árvore de decisão\n",
    "        min_samples_leaf = 1 # Número mínimo de registros em cada folha de cada árvore\n",
    "        \n",
    "    else:\n",
    "        n_estimators = random.randint(50,250)\n",
    "        max_depth = random.randint(3,10)\n",
    "        min_samples_leaf = random.randint(1,50)\n",
    "          \n",
    "    print(f\"Variation {i}; n_estimators = {n_estimators}; max_depth = {max_depth}; min_samples_leaf = {min_samples_leaf}\")      \n",
    "    model_6 = MultiOutputRegressor(RandomForestRegressor(n_jobs = -1,\n",
    "                                                         random_state = 23,\n",
    "                                                         n_estimators = n_estimators,\n",
    "                                                         max_depth = max_depth,\n",
    "                                                         min_samples_leaf = min_samples_leaf\n",
    "                                                ))\n",
    "          \n",
    "    rmse_pred_train, rmse_pred_test, rmse_prog = rolling_forecast_evaluation(dataset=df,\n",
    "                                model=model_6,\n",
    "                                pipeline=pipeline2,\n",
    "                                train_cutoff_dates=train_cutoff_dates,\n",
    "                                forecast_horizon=36,\n",
    "                                target_variables=[\"g_ver_t\"],\n",
    "                                baseline=baseline,\n",
    "                                show_test_plots=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    random_search_results[str(i)]={\n",
    "        \"n_estimators\":n_estimators,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_samples_leaf\":min_samples_leaf,\n",
    "        \"rmse_pred_train_avg\":mean(rmse_pred_train),\n",
    "        \"rmse_pred_train_stdev\":stdev(rmse_pred_train),\n",
    "        \"rmse_pred_test_avg\":mean(rmse_pred_test),\n",
    "        \"rmse_pred_test_stdev\":stdev(rmse_pred_test),\n",
    "        \"rmse_prog_avg\":mean(rmse_prog),\n",
    "        \"rmse_prog_stdev\":stdev(rmse_prog)\n",
    "    }\n",
    "\n",
    "df_random_search_results = pd.DataFrame.from_dict(random_search_results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results = df_random_search_results.sort_values(by=[\"rmse_pred_test_avg\"])\n",
    "df_random_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results.to_csv(r\"model_6_random_forest_random_search_results.csv\", encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results = pd.read_csv(r\"model_6_random_forest_random_search_results.csv\", encoding = \"utf-8\")\n",
    "df_random_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d1e5b",
   "metadata": {},
   "source": [
    "Hiperparâmetros selecionados para a floresta aleatória:\n",
    "- Número de estimadores: 100\n",
    "- Profundidade máxima da árvore: não limitada\n",
    "- Número mínimo de amostras por folha: 1\n",
    "\n",
    "Motivo para a escolha: estes hiperparâmetros foram usados no modelo que apresentou o menor erro de treinamento\n",
    "\n",
    "(Nota: estes são os hiperparâmetros padrão do regressor de floresta aleatória do _scikit-learn_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c298a7a9",
   "metadata": {},
   "source": [
    "### Modelo 7 - Light Gradient-boosted machine regressor com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422252c",
   "metadata": {},
   "source": [
    "#### Ajuste de hiperparâmetros - busca aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0bb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "\n",
    "random.seed(23) # inicializando o gerador de números pseudo-aleatórios com uma \"semente\" para que os resultados sejam os mesmos para cada vez que este código for executado\n",
    "\n",
    "random_search_results = {}\n",
    "\n",
    "df_random_search_results = pd.DataFrame()\n",
    "\n",
    "for i in range(40):\n",
    "\n",
    "    if i == 0: # utilize os hiperparâmetros padrão no primeiro modelo\n",
    "        lambda_l1 = 0 # regularização l1\n",
    "        max_depth = -1 # limite de altura de cada sub-árvore (neste caso, altura ilimitada)\n",
    "        num_leaves = 31 # número de folhas em cada sub-árvore treinada\n",
    "        min_data_in_leaf = 20 # número mínimo de registros em cada folha da árvore\n",
    "    else:\n",
    "        lambda_l1 = random.choice([random.uniform(0.0001, 0.0009), \n",
    "                                   random.uniform(0.001, 0.009),\n",
    "                                   random.uniform(0.01, 0.09),\n",
    "                                   random.uniform(0.1, 0.9),\n",
    "                                   random.uniform(1,9),\n",
    "                                   random.uniform(10,100)])\n",
    "        max_depth = random.randint(3,10)\n",
    "        num_leaves = random.randint((2**max_depth) // 2.5, (2**max_depth) // 1.5) # Ver https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "        min_data_in_leaf = random.randint(10,50)\n",
    "          \n",
    "    print(f\"Variation {i}; lambda_l1 = {lambda_l1}; max_depth = {max_depth}; num_leaves = {num_leaves}; min_data_in_leaf = {min_data_in_leaf}\")      \n",
    "    model_7 = MultiOutputRegressor(LGBMRegressor(boosting = \"gbdt\", \n",
    "                                                 linear_tree=True, \n",
    "                                                 lambda_l1=lambda_l1,\n",
    "                                                 max_depth=max_depth,\n",
    "                                                 num_leaves=num_leaves,\n",
    "                                                 min_data_in_leaf=min_data_in_leaf,\n",
    "                                                 verbose=-1\n",
    "                                                ))\n",
    "          \n",
    "    rmse_pred_train, rmse_pred_test, rmse_prog = rolling_forecast_evaluation(dataset=df,\n",
    "                                model=model_7,\n",
    "                                pipeline=pipeline2,\n",
    "                                train_cutoff_dates=train_cutoff_dates,\n",
    "                                forecast_horizon=36,\n",
    "                                target_variables=[\"g_ver_t\"],\n",
    "                                baseline=baseline,\n",
    "                                show_test_plots=False)\n",
    "    \n",
    "    random_search_results[str(i)]={\n",
    "        \"lambda_l1\":lambda_l1,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"num_leaves\":num_leaves,\n",
    "        \"min_data_in_leaf\":min_data_in_leaf,\n",
    "        \"rmse_pred_train_avg\":mean(rmse_pred_train),\n",
    "        \"rmse_pred_train_stdev\":stdev(rmse_pred_train),\n",
    "        \"rmse_pred_test_avg\":mean(rmse_pred_test),\n",
    "        \"rmse_pred_test_stdev\":stdev(rmse_pred_test),\n",
    "        \"rmse_prog_avg\":mean(rmse_prog),\n",
    "        \"rmse_prog_stdev\":stdev(rmse_prog)\n",
    "    }\n",
    "\n",
    "df_random_search_results = pd.DataFrame.from_dict(random_search_results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46887e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_random_search_results = df_random_search_results.sort_values(by=[\"rmse_pred_test_avg\"])\n",
    "df_random_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results.to_csv(r\"model_7_lightgbm_random_search_results.csv\", encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a68759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results = pd.read_csv(r\"model_7_lightgbm_random_search_results.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f54f08",
   "metadata": {},
   "source": [
    "#### Ajuste de hiperparâmetros - busca em grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "\n",
    "random.seed(23) # inicializando o gerador de números pseudo-aleatórios com uma \"semente\" para que os resultados sejam os mesmos para cada vez que este código for executado\n",
    "\n",
    "grid_search_results = {}\n",
    "\n",
    "df_grid_search_results = pd.DataFrame()\n",
    "\n",
    "lambda_l1 = 0.0001\n",
    "max_depth = [-1,8,9,10]\n",
    "num_leaves = [128, 256, 512] # Ver https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "min_data_in_leaf = [23,28,33]\n",
    "\n",
    "parameter_combinations = list(product(max_depth, num_leaves, min_data_in_leaf))\n",
    "\n",
    "for i, (max_depth, num_leaves, min_data_in_leaf) in enumerate(parameter_combinations):\n",
    "          \n",
    "    print(f\"Variation {i}; lambda_l1 = {lambda_l1}; max_depth = {max_depth}; num_leaves = {num_leaves}; min_data_in_leaf = {min_data_in_leaf}\")      \n",
    "    model_7 = MultiOutputRegressor(LGBMRegressor(boosting = \"gbdt\", \n",
    "                                                 linear_tree=True, \n",
    "                                                 lambda_l1=lambda_l1,\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 num_leaves=num_leaves,\n",
    "                                                 min_data_in_leaf=min_data_in_leaf,\n",
    "                                                 verbose=-1\n",
    "                                                ))\n",
    "          \n",
    "    rmse_pred_train, rmse_pred_test, rmse_prog = rolling_forecast_evaluation(dataset=df,\n",
    "                                model=model_7,\n",
    "                                pipeline=pipeline2,\n",
    "                                train_cutoff_dates=train_cutoff_dates,\n",
    "                                forecast_horizon=36,\n",
    "                                target_variables=[\"g_ver_t\"],\n",
    "                                baseline=baseline,\n",
    "                                show_test_plots=False)\n",
    "    \n",
    "    grid_search_results[str(i)]={\n",
    "        \"lambda_l1\":lambda_l1,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"num_leaves\":num_leaves,\n",
    "        \"min_data_in_leaf\":min_data_in_leaf,\n",
    "        \"rmse_pred_train_avg\":mean(rmse_pred_train),\n",
    "        \"rmse_pred_train_stdev\":stdev(rmse_pred_train),\n",
    "        \"rmse_pred_test_avg\":mean(rmse_pred_test),\n",
    "        \"rmse_pred_test_stdev\":stdev(rmse_pred_test),\n",
    "        \"rmse_prog_avg\":mean(rmse_prog),\n",
    "        \"rmse_prog_stdev\":stdev(rmse_prog)\n",
    "    }\n",
    "\n",
    "df_grid_search_results = pd.DataFrame.from_dict(grid_search_results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920bb2fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_grid_search_results = df_grid_search_results.sort_values(by=[\"rmse_pred_test_avg\"])\n",
    "df_grid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed20e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_search_results.to_csv(r\"model_7_lightgbm_grid_search_results.csv\", encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_search_results = pd.read_csv(r\"model_7_lightgbm_grid_search_results.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9b82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_grid_search_results[(df_grid_search_results[\"max_depth\"] == 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495d7e8",
   "metadata": {},
   "source": [
    "#### Ajuste de hiperparâmetros - busca aleatória (bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9634c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "\n",
    "random.seed(23) # inicializando o gerador de números pseudo-aleatórios com uma \"semente\" para que os resultados sejam os mesmos para cada vez que este código for executado\n",
    "\n",
    "random_search_results = {}\n",
    "\n",
    "df_random_search_results = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    lambda_l1 = 0.0001\n",
    "    max_depth = 8\n",
    "    num_leaves = random.randint(100,300)\n",
    "    min_data_in_leaf = random.randint(20,35)\n",
    "          \n",
    "    print(f\"Variation {i}; lambda_l1 = {lambda_l1}; max_depth = {max_depth}; num_leaves = {num_leaves}; min_data_in_leaf = {min_data_in_leaf}\")      \n",
    "    model_7 = MultiOutputRegressor(LGBMRegressor(boosting = \"gbdt\", \n",
    "                                                 linear_tree=True, \n",
    "                                                 lambda_l1=lambda_l1,\n",
    "                                                 max_depth=max_depth,\n",
    "                                                 num_leaves=num_leaves,\n",
    "                                                 min_data_in_leaf=min_data_in_leaf,\n",
    "                                                 verbose=-1\n",
    "                                                ))\n",
    "          \n",
    "    rmse_pred_train, rmse_pred_test, rmse_prog = rolling_forecast_evaluation(dataset=df,\n",
    "                                model=model_7,\n",
    "                                pipeline=pipeline2,\n",
    "                                train_cutoff_dates=train_cutoff_dates,\n",
    "                                forecast_horizon=36,\n",
    "                                target_variables=[\"g_ver_t\"],\n",
    "                                baseline=baseline,\n",
    "                                show_test_plots=False)\n",
    "    \n",
    "    random_search_results[str(i)]={\n",
    "        \"lambda_l1\":lambda_l1,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"num_leaves\":num_leaves,\n",
    "        \"min_data_in_leaf\":min_data_in_leaf,\n",
    "        \"rmse_pred_train_avg\":mean(rmse_pred_train),\n",
    "        \"rmse_pred_train_stdev\":stdev(rmse_pred_train),\n",
    "        \"rmse_pred_test_avg\":mean(rmse_pred_test),\n",
    "        \"rmse_pred_test_stdev\":stdev(rmse_pred_test),\n",
    "        \"rmse_prog_avg\":mean(rmse_prog),\n",
    "        \"rmse_prog_stdev\":stdev(rmse_prog)\n",
    "    }\n",
    "\n",
    "df_random_search_results = pd.DataFrame.from_dict(random_search_results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results = df_random_search_results.sort_values(by=[\"rmse_pred_test_avg\"])\n",
    "df_random_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results.to_csv(r\"model_7_lightgbm_random_search_results_2.csv\", encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43c7bf",
   "metadata": {},
   "source": [
    "Hiperparâmetros selecionados para o regressor Light GBM:\n",
    "- Regularização L1: 0.0001\n",
    "- Profundidade máxima de cada árvore: 8\n",
    "- Número mínimo de registros por folha em cada árvore: 23\n",
    "- Número de folhas em cada árvore: 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a074451",
   "metadata": {},
   "source": [
    "### Modelo 8 - Extreme gradient boosted trees com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445257ef",
   "metadata": {},
   "source": [
    "#### Ajuste de hiperparâmetros - busca aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fontes: https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
    "# https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "# https://medium.com/cmotions/hyperparameter-tuning-for-hyperaccurate-xgboost-model-d6e6b8650a11#:~:text=Typically%20used%20values%20are%200.4,its%20default%20value%20is%201.\n",
    "\n",
    "\n",
    "random.seed(23) # inicializando o gerador de números pseudo-aleatórios com uma \"semente\" para que os resultados sejam os mesmos para cada vez que este código for executado\n",
    "\n",
    "random_search_results = {}\n",
    "\n",
    "df_random_search_results = pd.DataFrame()\n",
    "\n",
    "for i in range(40):\n",
    "\n",
    "    if i == 0: # utilize os hiperparâmetros padrão no primeiro modelo\n",
    "        eta = 0.3 # Taxa de aprendizagem. \n",
    "        n_estimators = 100 # Número de árvores treinadas no processo de treinamento do modelo\n",
    "        max_depth = 6 # Profundidade máxima de cada árvore treinada\n",
    "        min_child_weight = 1 # Valor mínimo para a soma dos pesos em cada nó das árvores\n",
    "        reg_lambda = 1 # Regularização L2\n",
    "        subsample = 1 # Proporção de registros de treino utilizados no treinamento das árvores\n",
    "    else:\n",
    "        eta = random.uniform(0.01,0.3)\n",
    "        n_estimators = random.randint(50,300)\n",
    "        max_depth = random.randint(3,10)\n",
    "        min_child_weight = random.randint(1,7)        \n",
    "        reg_lambda = random.choice([random.uniform(0.0001, 0.0009), \n",
    "                                   random.uniform(0.001, 0.009),\n",
    "                                   random.uniform(0.01, 0.09),\n",
    "                                   random.uniform(0.1, 0.9),\n",
    "                                   random.uniform(1,9),\n",
    "                                   random.uniform(10,100)])\n",
    "        subsample = random.uniform(0.5,1)\n",
    "          \n",
    "    print(f\"Variation {i}; eta = {eta}; n_estimators = {n_estimators}; max_depth = {max_depth}; min_child_weight = {min_child_weight}; reg_lambda = {reg_lambda}; subsample = {subsample}\")      \n",
    "    model_8 = MultiOutputRegressor(XGBRegressor(verbosity = 0, silent=True,\n",
    "                                               eta=eta,\n",
    "                                               n_estimators=n_estimators,\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_child_weight=min_child_weight,\n",
    "                                               reg_lambda=reg_lambda,\n",
    "                                               subsample=subsample))\n",
    "          \n",
    "    rmse_pred_train, rmse_pred_test, rmse_prog = rolling_forecast_evaluation(dataset=df,\n",
    "                                model=model_8,\n",
    "                                pipeline=pipeline2,\n",
    "                                train_cutoff_dates=train_cutoff_dates,\n",
    "                                forecast_horizon=36,\n",
    "                                target_variables=[\"g_ver_t\"],\n",
    "                                baseline=baseline,\n",
    "                                show_test_plots=False)\n",
    "    \n",
    "    random_search_results[str(i)]={\n",
    "        \"eta\":eta,\n",
    "        \"n_estimators\":n_estimators,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"reg_lambda\":reg_lambda,\n",
    "        \"subsample\":subsample,\n",
    "        \"rmse_pred_train_avg\":mean(rmse_pred_train),\n",
    "        \"rmse_pred_train_stdev\":stdev(rmse_pred_train),\n",
    "        \"rmse_pred_test_avg\":mean(rmse_pred_test),\n",
    "        \"rmse_pred_test_stdev\":stdev(rmse_pred_test),\n",
    "        \"rmse_prog_avg\":mean(rmse_prog),\n",
    "        \"rmse_prog_stdev\":stdev(rmse_prog)\n",
    "    }\n",
    "\n",
    "df_random_search_results = pd.DataFrame.from_dict(random_search_results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cfb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results = df_random_search_results.sort_values(by=[\"rmse_pred_test_avg\"])\n",
    "df_random_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_search_results.to_csv(r\"model_8_xgboost_random_search_results.csv\", encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb677b",
   "metadata": {},
   "source": [
    "#### Ajuste de hiperparâmetros - busca em grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799986ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fontes: https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
    "# https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "# https://medium.com/cmotions/hyperparameter-tuning-for-hyperaccurate-xgboost-model-d6e6b8650a11#:~:text=Typically%20used%20values%20are%200.4,its%20default%20value%20is%201.\n",
    "\n",
    "\n",
    "random.seed(23) # inicializando o gerador de números pseudo-aleatórios com uma \"semente\" para que os resultados sejam os mesmos para cada vez que este código for executado\n",
    "\n",
    "grid_search_results = {}\n",
    "\n",
    "df_grid_search_results = pd.DataFrame()\n",
    "\n",
    "eta = [0.05, 0.1, 0.15]\n",
    "n_estimators = [150,200,250]\n",
    "max_depth = [4,7]\n",
    "min_child_weight = 5    \n",
    "reg_lambda = 5\n",
    "subsample = [0.9,0.95]\n",
    "\n",
    "parameter_combinations = list(product(eta, n_estimators, max_depth, subsample))\n",
    "\n",
    "for i, (eta, n_estimators, max_depth, subsample) in enumerate(parameter_combinations):    \n",
    "    print(f\"Variation {i}; eta = {eta}; n_estimators = {n_estimators}; max_depth = {max_depth}; min_child_weight = {min_child_weight}; reg_lambda = {reg_lambda}; subsample = {subsample}\")      \n",
    "    model_8 = MultiOutputRegressor(XGBRegressor(verbosity = 0, silent=True,\n",
    "                                               eta=eta,\n",
    "                                               n_estimators=n_estimators,\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_child_weight=min_child_weight,\n",
    "                                               reg_lambda=reg_lambda,\n",
    "                                               subsample=subsample))\n",
    "          \n",
    "    rmse_pred_train, rmse_pred_test, rmse_prog = rolling_forecast_evaluation(dataset=df,\n",
    "                                model=model_8,\n",
    "                                pipeline=pipeline2,\n",
    "                                train_cutoff_dates=train_cutoff_dates,\n",
    "                                forecast_horizon=36,\n",
    "                                target_variables=[\"g_ver_t\"],\n",
    "                                baseline=baseline,\n",
    "                                show_test_plots=False)\n",
    "    \n",
    "    grid_search_results[str(i)]={\n",
    "        \"eta\":eta,\n",
    "        \"n_estimators\":n_estimators,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"reg_lambda\":reg_lambda,\n",
    "        \"subsample\":subsample,\n",
    "        \"rmse_pred_train_avg\":mean(rmse_pred_train),\n",
    "        \"rmse_pred_train_stdev\":stdev(rmse_pred_train),\n",
    "        \"rmse_pred_test_avg\":mean(rmse_pred_test),\n",
    "        \"rmse_pred_test_stdev\":stdev(rmse_pred_test),\n",
    "        \"rmse_prog_avg\":mean(rmse_prog),\n",
    "        \"rmse_prog_stdev\":stdev(rmse_prog)\n",
    "    }\n",
    "\n",
    "df_grid_search_results = pd.DataFrame.from_dict(grid_search_results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d27324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_search_results.to_csv(r\"model_8_xgboost_grid_search_results.csv\", encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_search_results = df_grid_search_results.sort_values(by=[\"rmse_pred_test_avg\"])\n",
    "df_grid_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b33057",
   "metadata": {},
   "source": [
    "Hiperparâmetros selecionados para o regressor XGBoost:\n",
    "- Taxa de aprendizagem: 0.10\n",
    "- Número de estimadores: 150\n",
    "- Profundidade máxima de cada estimador: 7\n",
    "- Peso mínimo de cada nó filho: 5\n",
    "- Regularização L2: 5\t\n",
    "- Taxa de amostragem em cada estimador: 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ee32c",
   "metadata": {},
   "source": [
    "Nota: o desempenho de vários modelos na previsão da geração de energia eólica utilizando os dados de treinamento foi mais baixo do que na previsão que utilizou dados de teste. Esperava-se que o desempenho da previsão que utilizou os dados de treinamento seria maior do que a previsão que utilizou os dados de teste.\n",
    "\n",
    "Uma possível causa para esta diferença se encontra no baixo número de ensaios de teste, tendo em vista que o desempenho da previsão com dados de teste foi computada apenas para um único horizonte de previsão. Assim, é possível que as medidas de desempenho do modelos em ensaios de teste tenham sido superestimados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6646c5e",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos ajustados e previsão da geração eólica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a872522",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_dates = [\"2023-10-7\",\"2023-10-8\",\"2023-10-9\",\"2023-10-10\",\"2023-10-11\",\"2023-10-12\",\"2023-10-13\"]\n",
    "forecast_horizon = 36\n",
    "target_variables=[\"g_ver_t\"]\n",
    "dataset = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_train_test(dataset=dataset, \n",
    "                                                    cutoff_date=cutoff_dates[0], \n",
    "                                                    forecast_horizon = forecast_horizon, \n",
    "                                                    target_variables=target_variables)\n",
    "\n",
    "X_train_transformed, y_train_transformed = transform_features_train_set(pipeline2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa61d0",
   "metadata": {},
   "source": [
    "### Modelo 5 - Regressão linear regularizada Ridge com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37633f99",
   "metadata": {},
   "source": [
    "Hiperparâmetro selecionado para o regressor linear Ridge:\n",
    "- Alpha: 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e660e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Ridge(alpha=0.0001)\n",
    "\n",
    "model_5.fit(X_train_transformed, y_train_transformed)\n",
    "\n",
    "rmse_pred_train=[]  \n",
    "rmse_pred_test=[]\n",
    "rmse_prog=[]\n",
    "\n",
    "# Estimação do desempenho do modelo de predição quando aplicado ao conjunto de teste\n",
    "for cutoff_date in cutoff_dates:\n",
    "    print(f\"Previsão da geração eólica de {forecast_horizon} horas a partir de {cutoff_date}\")\n",
    "    forecasted_values, rmse_predicted_test, rmse_baseline = make_forecast_wind_generation(\n",
    "        model=model_5, X=X_test, y=y_test, \n",
    "        target_variables=target_variables, \n",
    "        forecast_point_start=cutoff_date,\n",
    "        forecast_horizon=forecast_horizon, pipeline=pipeline2, baseline=baseline)\n",
    "    \n",
    "    print(f\"RMSE da previsão: {rmse_predicted_test}; RMSE da programação: {rmse_baseline}\\n\")\n",
    "    rmse_pred_test.append(rmse_predicted_test)\n",
    "    rmse_prog.append(rmse_baseline)\n",
    "\n",
    "print(f\"\\nRMSE médio da previsão: {mean(rmse_pred_test)}\")\n",
    "print(f\"RMSE médio da programação: {mean(rmse_prog)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(np.abs(model_5.coef_[0]))\n",
    "feature_importances.index = X_train_transformed.columns\n",
    "feature_importances = feature_importances.sort_values()\n",
    "feature_importances.plot.barh(title=\"Importância dos atributos - Regressão linear Ridge\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d707a5c6",
   "metadata": {},
   "source": [
    "### Modelo 6 - Floresta aleatória com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227fb28",
   "metadata": {},
   "source": [
    "Hiperparâmetros selecionados para a floresta aleatória:\n",
    "- Número de estimadores: 100\n",
    "- Profundidade máxima da árvore: não limitada\n",
    "- Número mínimo de amostras por folha: 1\n",
    "\n",
    "(Nota: estes são os hiperparâmetros padrão do regressor de floresta aleatória do _scikit-learn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = RandomForestRegressor(n_jobs = -1,\n",
    "                                random_state = 23,\n",
    "                                n_estimators = 100,\n",
    "                                max_depth = None,\n",
    "                                min_samples_leaf = 1\n",
    "                               )\n",
    "\n",
    "model_6.fit(X_train_transformed, y_train_transformed)\n",
    "\n",
    "rmse_pred_train=[]  \n",
    "rmse_pred_test=[]\n",
    "rmse_prog=[]\n",
    "\n",
    "# Estimação do desempenho do modelo de predição quando aplicado ao conjunto de teste\n",
    "for cutoff_date in cutoff_dates:\n",
    "    print(f\"Previsão da geração eólica de {forecast_horizon} horas a partir de {cutoff_date}\")\n",
    "    forecasted_values, rmse_predicted_test, rmse_baseline = make_forecast_wind_generation(\n",
    "        model=model_6, X=X_test, y=y_test, \n",
    "        target_variables=target_variables, \n",
    "        forecast_point_start=cutoff_date,\n",
    "        forecast_horizon=forecast_horizon, pipeline=pipeline2, baseline=baseline)\n",
    "    \n",
    "    print(f\"RMSE da previsão: {rmse_predicted_test}; RMSE da programação: {rmse_baseline}\\n\")\n",
    "    rmse_pred_test.append(rmse_predicted_test)\n",
    "    rmse_prog.append(rmse_baseline)\n",
    "\n",
    "print(f\"\\nRMSE médio da previsão: {mean(rmse_pred_test)}\")\n",
    "print(f\"RMSE médio da programação: {mean(rmse_prog)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(np.abs(model_6.feature_importances_))\n",
    "feature_importances.index = X_train_transformed.columns\n",
    "feature_importances = feature_importances.sort_values()\n",
    "feature_importances.plot.barh(title=\"Importância dos atributos - Floresta Aleatória\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aaf090",
   "metadata": {},
   "source": [
    "### Modelo 7 - Light Gradient Boosted Machine com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a621b0c",
   "metadata": {},
   "source": [
    "Hiperparâmetros selecionados para o regressor Light GBM:\n",
    "- Regularização L1: 0.0001\n",
    "- Profundidade máxima de cada árvore: 8\n",
    "- Número mínimo de registros por folha em cada árvore: 23\n",
    "- Número de folhas em cada árvore: 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = LGBMRegressor(boosting = \"gbdt\", \n",
    "                                             linear_tree=True, \n",
    "                                             lambda_l1=0.0001,\n",
    "                                             max_depth = 8,\n",
    "                                             min_data_in_leaf=23,\n",
    "                                             num_leaves=128,\n",
    "                                             verbose=-1\n",
    "                                            )\n",
    "\n",
    "model_7.fit(X_train_transformed, y_train_transformed)\n",
    "\n",
    "rmse_pred_train=[]  \n",
    "rmse_pred_test=[]\n",
    "rmse_prog=[]\n",
    "\n",
    "# Estimação do desempenho do modelo de predição quando aplicado ao conjunto de teste\n",
    "for cutoff_date in cutoff_dates:\n",
    "    print(f\"Previsão da geração eólica de {forecast_horizon} horas a partir de {cutoff_date}\")\n",
    "    forecasted_values, rmse_predicted_test, rmse_baseline = make_forecast_wind_generation(\n",
    "        model=model_7, X=X_test, y=y_test, \n",
    "        target_variables=target_variables, \n",
    "        forecast_point_start=cutoff_date,\n",
    "        forecast_horizon=forecast_horizon, pipeline=pipeline2, baseline=baseline)\n",
    "    \n",
    "    print(f\"RMSE da previsão: {rmse_predicted_test}; RMSE da programação: {rmse_baseline}\\n\")\n",
    "    rmse_pred_test.append(rmse_predicted_test)\n",
    "    rmse_prog.append(rmse_baseline)\n",
    "\n",
    "print(f\"\\nRMSE médio da previsão: {mean(rmse_pred_test)}\")\n",
    "print(f\"RMSE médio da programação: {mean(rmse_prog)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(np.abs(model_7.feature_importances_))\n",
    "feature_importances.index = X_train_transformed.columns\n",
    "feature_importances = feature_importances.sort_values()\n",
    "feature_importances.plot.barh(title=\"Importância dos atributos - Light Gradient Boosted Machine Regressor\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07ad21",
   "metadata": {},
   "source": [
    "### Modelo 8 - Extreme Gradient Boosted Machine com previsão do tempo \"perfeita\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558d31f",
   "metadata": {},
   "source": [
    "Hiperparâmetros selecionados para o regressor XGBoost:\n",
    "- Taxa de aprendizagem: 0.10\n",
    "- Número de estimadores: 150\n",
    "- Profundidade máxima de cada estimador: 7\n",
    "- Peso mínimo de cada nó filho: 5\n",
    "- Regularização L2: 5\t\n",
    "- Taxa de amostragem em cada estimador: 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8 = XGBRegressor(verbosity = 0, silent=True,\n",
    "                                           eta=0.10,\n",
    "                                           n_estimators=150,\n",
    "                                           max_depth=7,\n",
    "                                           min_child_weight=5,\n",
    "                                           reg_lambda=5,\n",
    "                                           subsample=0.90)\n",
    "\n",
    "model_8.fit(X_train_transformed, y_train_transformed)\n",
    "\n",
    "rmse_pred_train=[]  \n",
    "rmse_pred_test=[]\n",
    "rmse_prog=[]\n",
    "\n",
    "# Estimação do desempenho do modelo de predição quando aplicado ao conjunto de teste\n",
    "for cutoff_date in cutoff_dates:\n",
    "    print(f\"Previsão da geração eólica de {forecast_horizon} horas a partir de {cutoff_date}\")\n",
    "    forecasted_values, rmse_predicted_test, rmse_baseline = make_forecast_wind_generation(\n",
    "        model=model_8, X=X_test, y=y_test, \n",
    "        target_variables=target_variables, \n",
    "        forecast_point_start=cutoff_date,\n",
    "        forecast_horizon=forecast_horizon, pipeline=pipeline2, baseline=baseline)\n",
    "    \n",
    "    print(f\"RMSE da previsão: {rmse_predicted_test}; RMSE da programação: {rmse_baseline}\\n\")\n",
    "    rmse_pred_test.append(rmse_predicted_test)\n",
    "    rmse_prog.append(rmse_baseline)\n",
    "\n",
    "print(f\"\\nRMSE médio da previsão: {mean(rmse_pred_test)}\")\n",
    "print(f\"RMSE médio da programação: {mean(rmse_prog)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(np.abs(model_8.feature_importances_))\n",
    "feature_importances.index = X_train_transformed.columns\n",
    "feature_importances = feature_importances.sort_values()\n",
    "feature_importances.plot.barh(title=\"Importância dos atributos - Extreme Gradient Boosted Regressor\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e2352e",
   "metadata": {},
   "source": [
    "## Avaliação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252ea91",
   "metadata": {},
   "source": [
    "Programação do ONS\n",
    "- RMSE: 39.028 MW-médio horário\n",
    "\n",
    "Regressor linear Ridge com previsão do tempo \"perfeita\"\n",
    "- RMSE: 47.843 MW-médio horário\n",
    "\n",
    "\n",
    "Regressor Floresta Aleatória com previsão do tempo \"perfeita\"\n",
    "- RMSE: 41.693 MW-médio horário\n",
    "\n",
    "\n",
    "Regressor Light Gradient Boosted Machine com previsão do tempo \"perfeita\"\n",
    "- RMSE: 40.317 MW-médio horário\n",
    "\n",
    "\n",
    "Regressor Extreme Gradient Boosted com previsão do tempo \"perfeita\"\n",
    "- RMSE: 40.247 MW-médio horário\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
